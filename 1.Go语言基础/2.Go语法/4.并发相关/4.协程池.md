既然`Goroutine`本身已经非常轻量（初始栈仅约`2KB`，由`Go`运行时自动伸缩），为什么还要引入协程池呢？

即使初始栈只有`2KB`，`Goroutine`在创建、调度和销毁过程中仍需由`Go`运行时执行额外操作，例如分配栈空间、将其注册到`M`和`P`的调度结构中，以及处理调度器负载。当并发数量达到`10`万级甚至百万级时，这些成本会明显上升。

许多业务并非纯计算，而是`IO`密集或依赖外部系统（例如`MySQL`、`Redis`、消息队列、第三方接口）。这些系统本身就存在并发限制：数据库连接池通常只能维持几十到几百个连接，下游接口往往具备`QPS`约束，文件系统也可能受到限制。如果每个请求都开一个`Goroutine`，超出下游能力后会拉跨整个系统。

`Goroutine`数量过多会显著增加`GC`在标记阶段扫描根对象的成本，从而拉长`STW`时间。`Go`的`GC`采用并发标记-清扫算法，在标记开始前会不可避免地存在一个短暂的`STW`阶段，用于确定并扫描根对象（`GC Roots`），其中就包括各个`Goroutine`的栈。

随着`Goroutine`数量增加，需要扫描的栈数量线性增长，整体扫描开销随之上升。`GC`在`STW`阶段需要遍历并记录所有`Goroutine`的栈信息，该过程无法完全并发执行。最终表现为`Goroutine`越多，`STW`阶段耗时越长，停顿时间的抖动也越明显。

> `Go`中的协程池与`Java`中的线程池在设计目标上存在本质差异：前者主要用于限制同时活跃的`Goroutine`数量，以控制并发规模；后者则侧重于复用线程对象，降低线程创建和销毁带来的开销。

在`Go`语言中，可以通过`channel`来限制并发执行的协程数量，示例代码如下：

```go
type Task func()

type Pool struct {
	workerNum int // 表示协程池允许多少个协程同时执行任务
	taskChan  chan Task
	wg        sync.WaitGroup
}

func NewPool(workerNum int) *Pool {
	return &Pool{
		workerNum: workerNum,
		taskChan:  make(chan Task),
	}
}

func (p *Pool) Start() {
	for i := 0; i < p.workerNum; i++ {
		go func() {
			for task := range p.taskChan {
				task()
				p.wg.Done()
			}
		}()
	}
}

func (p *Pool) Submit(task Task) {
	p.wg.Add(1)
	p.taskChan <- task
}

func (p *Pool) Wait() {
	p.wg.Wait()
	close(p.taskChan)
}

func main() {
	pool := NewPool(10)
	pool.Start()
	for i := 0; i < 100; i++ {
		num := i
		pool.Submit(func() {
			fmt.Println("task:", num)
			time.Sleep(500 * time.Millisecond)
		})
	}
	pool.Wait()
	fmt.Println("all tasks done")
}
```

我们也可以使用下面这个成熟的高性能协程池库：

```sh
go get github.com/panjf2000/ants/v2
```

使用该库后，上述手动实现的协程池可以通过更简洁的方式完成同样的功能，代码如下：

```go
func main() {
	var wg sync.WaitGroup
	pool, _ := ants.NewPool(10)
	defer pool.Release()
	for i := 0; i < 100; i++ {
		wg.Add(1)
		num := i
		_ = pool.Submit(func() {
			defer wg.Done()
			fmt.Println("task:", num)
			time.Sleep(500 * time.Millisecond)
		})
	}
	wg.Wait()
	fmt.Println("all tasks done")
}
```

无论是我手写的`Pool`，还是`ants`，它们的最小职责都只有一件事：限制同时活跃的`Goroutine`数量。因此，这类协程池并不会、也不应该关注协程内部发生的错误该如何处理。如果需要在`main`函数中感知并处理协程执行过程中可能返回的`err`，正确的做法是通过一个`channel`对错误进行集中收集，并在所有协程执行完成之后，再对这些错误进行统一处理：

```go
func main() {
	var wg sync.WaitGroup
	pool, _ := ants.NewPool(10)
	defer pool.Release()
	errCh := make(chan error, 100)
	for i := 0; i < 100; i++ {
		wg.Add(1)
		num := i
		_ = pool.Submit(func() {
			defer wg.Done()
			if err := doTask(num); err != nil {
				errCh <- err
			}
		})
	}
	wg.Wait()
	close(errCh)
	for err := range errCh {
		fmt.Println("task error:", err)
	}
	fmt.Println("all tasks done")
}
```

