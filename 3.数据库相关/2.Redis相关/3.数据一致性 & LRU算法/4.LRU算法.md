前面在`Redis`的内存淘汰机制中，提到了`Redis`最常用的淘汰策略就是`LRU`，下面我们讲一下。

`LRU`：`Least Recently Used`，最近最少使用，是一种常用的缓存淘汰策略。其核心思想是基于数据的历史访问记录，即最近最少使用的数据会被优先淘汰。

`LRU`缓存的实现结合了哈希表和双向链表，各自承担不同的职责：

1. 哈希表：用于快速查找缓存中的数据。通过哈希表可以在常数时间内定位到数据的位置。
2. 双向链表：用于维护数据的访问顺序。双向链表的头部表示最近访问的数据，尾部表示最久未访问的数据。

`LRU`工作原理如下所示：

- 数据访问：当数据被访问时，首先检查哈希表。如果数据已存在，则将数据节点移动到链表的头部，表示它是最近访问的。
- 数据添加：如果数据不在缓存中，从数据库中读取数据，并将其添加到链表的头部。同时，更新哈希表以存储该数据的位置。
- 容量管理：当缓存达到预设容量时，从链表的尾部移除最久未被访问的数据节点，以腾出空间给新数据。此操作同时更新哈希表，删除尾部的节点，并把新数据放到头部节点。

假设现在缓存中有这四个数据：

<img src="image/2b62e48a405e4f9abc00b0ac75668f5b.png" alt="在这里插入图片描述" style="zoom: 67%;" />

当访问用户`5`时，发现哈希链表中没有这个数据，从数据库中读出来，插入到链表中：

<img src="image/f69cfe6e5702433a87e77735afe4acf5.png" alt="在这里插入图片描述" style="zoom:67%;" />

当访问用户`2`时，由于哈希链表中有用户`2`的数据，我们把它掐断，放到链表最右端，表示它是最近使用的。

<img src="image/bd837ad0ae914f528eeec0a5e6096d5b.png" alt="在这里插入图片描述" style="zoom:67%;" />

同理访问用户`4`：

<img src="image/a5e6bcc244a64079a817d74b2418cf00.png" alt="在这里插入图片描述" style="zoom:67%;" />

当访问用户`6`，用户`6`在缓存中没有，需要读库，插入到链表中，但此时链表长度已满，我们把最左端的用户`1`删掉，然后插入用户`6`。

<img src="image/dfc3f35014774ce793e20bd2a1225f29.png" alt="在这里插入图片描述" style="zoom:67%;" />

用`Go`语言完成代码编写：

```go
type Node struct {
	key, value int
	prev, next *Node
}

type LRUCache struct {
	capacity   int
	cache      map[int]*Node
	head, tail *Node
}

func Constructor(capacity int) *LRUCache {
	head := &Node{}
	tail := &Node{}
	head.next = tail
	tail.prev = head
	return &LRUCache{
		capacity: capacity,
		cache:    make(map[int]*Node),
		head:     head,
		tail:     tail,
	}
}

func (c *LRUCache) addNode(node *Node) {
	node.prev = c.head
	node.next = c.head.next
	c.head.next.prev = node
	c.head.next = node
}

func (c *LRUCache) removeNode(node *Node) {
	node.prev.next = node.next
	node.next.prev = node.prev
}

func (c *LRUCache) moveToHead(node *Node) {
	c.removeNode(node)
	c.addNode(node)
}

func (c *LRUCache) get(key int) int {
	if node, found := c.cache[key]; found {
		c.moveToHead(node)
		return node.value
	}
	return -1
}

func (c *LRUCache) put(key, value int) {
	if node, found := c.cache[key]; found {
		node.value = value
		c.moveToHead(node)
	} else {
		if len(c.cache) == c.capacity {
			tailKey := c.tail.prev.key
			c.removeNode(c.tail.prev)
			delete(c.cache, tailKey)
		}
		newNode := &Node{key: key, value: value}
		c.cache[key] = newNode
		c.addNode(newNode)
	}
}
```

