缓存击穿是指当一个经常被访问的热`Key`的缓存过期时，大量请求会同时访问这个`Key`，瞬间绕过缓存服务器直接访问数据库。这会导致数据库的访问压力急剧增加，可能引发数据库过载。

对于缓存击穿和缓存穿透的概念要进行细致区分：

- 缓存穿透：请求的数据在缓存和数据库中都不存在，大量请求绕过缓存直接访问数据库，导致并发问题。
- 缓存击穿：请求的数据在数据库中存在，在高并发情况下，由于某时刻缓存过期，大量请求同时访问数据库。

如何解决缓存击穿？我们有如下几种解决方案：

### 1. 设置热点`Key`永不过期

方式一：不直接将热点`Key`的存活时间设置为永久，而是通过启动后台异步任务，定期检查热点`Key`的`TTL`。当检测到某个热点`Key`的`TTL`低于预设阈值时，从数据库读取最新数据刷新到缓存中，并同步更新其`TTL`。

方式二：不给热点`Key`设置物理过期时间，而是在缓存`Value`中维护一个逻辑过期时间字段。此时，缓存中存储的不再是业务对象本身，而是包含业务数据及逻辑过期信息的包装结构。例如：

```go
type CacheData[T any] struct {
    Data       T
    ExpireTime time.Time
}
```

我们将其序列化后整体存入`Redis`。代码在获取缓存后，会先判断其是否发生逻辑过期；若已过期，则只允许一个线程执行缓存重建，其余线程直接使用旧数据，该过程可以通过`Redis`分布式锁来实现。

> 不能仅通过将热点`Key`设置为永不过期来解决缓存击穿问题。因为一旦发生写缓存失败，就可能产生“永久脏数据”，错误缓存生成后缺乏任何自动修复的兜底机制，只能依赖人工介入处理。此外，即便不为`Key`设置过期时间，仍然可能因`Redis`重启、主从切换、内存淘汰或人为清空缓存等原因导致缓存瞬间失效，进而使所有请求同时直接打到数据库。

### 2. 使用互斥锁

当缓存过期时，只有第一个访问缓存的线程会去查询数据库，其余线程则等待该线程完成查询并更新缓存。这样做的目的是降低数据库压力，避免大量请求同时访问数据库。

但在高并发场景下，这种方案的问题会被放大。例如，当有`1000`个请求同时到达时，其中`999`个线程会因互斥锁而被阻塞，极易导致用户请求等待甚至超时。该方案虽然在一定程度上缓解了数据库压力，但并未从根本上解决高并发带来的系统吞吐和响应时延问题。因此，在高并发场景下，应尽量避免通过加锁的方式来处理缓存重建。

以下是使用互斥锁解决缓存击穿的代码示例：

~~~ go
var (
	redisClient *redis.Client
	mutex = &sync.Mutex{}
	ctx   = context.Background()
)

func getValueFromCache(key string) (string, error) {
	val, err := redisClient.Get(ctx, key).Result()
	if err == redis.Nil {
		mutex.Lock()
		defer mutex.Unlock()
		// 这里省略了从数据库中获取数据的代码
		dbValue := "get value from database"
		redisClient.Set(ctx, key, dbValue, 10*time.Minute)
		val = dbValue
	}
	return val, err
}

func main() {
	redisClient = redis.NewClient(&redis.Options{
		Addr: "localhost:6379",
	})
	var wg sync.WaitGroup
	for i := 0; i < 5; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			value, _ := getValueFromCache("my_key")
			fmt.Printf("get value from cache: %s\n", value)
		}()
	}
	wg.Wait()
}
~~~

如果系统中有多个服务节点，应该通过`Redis`的分布式锁来实现加锁操作，在后续章节会对其进行详细讲解。

### 3. 定时刷新

该方案与第一种解决思路本质上类似。可以在后台启动一个定时任务，假设某热点`Key`的存活时间为`10`分钟，则每隔`9`分钟执行一次任务，从数据库中读取最新数据并更新到缓存中，同时刷新缓存的存活时间。

### 4. 缓存预热

在系统启动时进行缓存的预热，加载一些核心数据到缓存中，避免启动后大量请求落到数据库。