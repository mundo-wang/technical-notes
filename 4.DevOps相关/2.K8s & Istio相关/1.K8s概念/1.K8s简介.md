应用的部署经历了三个重要的发展阶段：

1. 传统部署：应用程序直接部署在物理服务器上，通常每个应用会独占一部分服务器资源，也可能在同一台服务器上部署多个应用，但需要为每个应用手动配置端口和依赖环境。整体来看，部署和扩展过程复杂且耗时，资源利用率偏低；由于不同应用之间缺乏有效隔离，容易发生依赖冲突，同时也难以充分共享服务器的计算资源。
2. 虚拟化部署：使用虚拟化技术（如`VMware`、`Hyper-V`）可以将单台物理服务器划分为多个虚拟机，每个虚拟机运行独立的操作系统和应用程序。虚拟化提升了资源利用率，并借助虚拟机镜像简化了应用的迁移、复制与扩展。不同虚拟机之间相互隔离，从而增强了部署灵活性和系统安全性，同时显著降低了环境冲突的风险。
3. 容器化部署：容器化技术（如`Docker`）将应用及其全部依赖打包进容器中运行，由于容器共享宿主机操作系统内核，因此相较虚拟机更加轻量、启动更快。容器同时具备良好的隔离性与可移植性，可在任何支持容器的平台上运行。通过容器化部署，可以显著提升资源利用率，简化应用的扩展与运维管理，并天然适配微服务架构，使整体部署流程更加快速高效。

`Kubernetes`简称为`K8s`，是一个开源的容器编排平台，专门用于自动化容器化应用程序的部署、扩展和管理。它为容器集群提供了一套强大的工具，使得应用管理更加高效和可靠。那么，既然已经有了`Docker`，为什么还需要引入`K8s`呢？

虽然`Docker`解决了应用容器化的问题，但随着系统复杂度和规模的提升，其局限性逐步显现。首先，`Docker`本身不具备跨多台服务器进行容器编排和统一管理的能力，而`K8s`提供了自动调度、服务发现和负载均衡等集群级能力。其次，`K8s`支持自动扩缩容和自愈机制，能够根据流量变化动态调整容器实例数量，并在容器发生故障时自动重启，从而保障服务的高可用性。此外，`K8s`在持久化存储和资源隔离方面提供了更灵活的机制，能够支持多租户场景和复杂的资源管理需求，而`Docker`在这些方面相对不足。

尽管`Docker Compose`也可以用于管理多个容器，但其主要适用于单机环境，更偏向开发和测试场景。在生产环境，尤其是分布式系统中，`Docker Compose`存在明显局限，它无法进行跨节点编排，缺乏`Kubernetes`的集群管理能力，也不支持自动扩缩容、自愈以及完善的服务发现机制。除此之外，它对持久化存储的支持较为有限，无法像`Kubernetes`那样对存储资源进行统一且灵活的管理。

在云原生环境中，由于需要管理复杂的集群与服务，通常依赖`Kubernetes`提供全面的自动化编排与运维能力。因此，在涉及跨服务器部署、自动扩缩容以及复杂服务治理的场景下，`K8s`有不可替代的优势。简而言之，`Docker Compose`更适合小规模、单节点应用的容器编排，而`Kubernetes`则更适用于大规模、分布式以及生产环境中的容器统一管理。

`K8s`主要提供以下关键功能：

- 自我修复：`K8s`能够快速检测并替换崩溃的容器，确保应用的持续可用性。
- 服务发现：应用程序可以通过自动发现机制找到所需服务，简化配置并提高系统的可靠性。
- 弹性伸缩：`K8s`根据负载需求自动调整容器数量，实现高效资源利用和动态扩展。
- 负载均衡：`K8s`自动将请求均衡分配到多个容器实例，优化性能并保证稳定的服务响应。
- 版本回退：支持快速回滚到稳定版本，确保在新版本出现问题时能够及时恢复系统的稳定性。
- 存储编排：`K8s`根据容器需求动态创建和分配存储卷，增强应用数据的持久性。

`K8s`的本质是由一组服务器集群组成的。一个`K8s`集群由一个控制节点（`Master`）和多个工作节点（`Node`）构成。有关`Master`节点和`Node`节点组件的详细说明，请参见后续两个章节。下图介绍了`K8s`集群的工作原理：

![img](image/c11fed5e227b29279e526163623a79e6.png)

在`Kubernetes`系统中部署一个`Nginx`服务时，各组件之间的调用关系如下：

1. `Kubernetes`环境启动后，`Master`和`Node`节点会将自身信息存储到`Etcd`数据库中。
2. 安装`Nginx`的请求首先发送到`Master`节点的`API Server`组件。
3. `API Server`调用`Scheduler`组件，以决定将服务安装到哪个`Node`节点上。`Scheduler`从`Etcd`中读取`Node`节点的信息，按照特定算法选择目标节点，将决策写入`Etcd`并通知`API Server`。
4. `API Server`接着调用目标`Node`节点上的`Kubelet`，指示其在该`Node`上安装`Nginx`服务。
5. `Kubelet`接收到指令后，通知`Docker`启动一个`Nginx`的`Pod`。`Pod`是`Kubernetes`的最小部署单元，容器必须运行在`Pod`中。
6. `Nginx`服务成功运行后，外部用户可以通过`Kube-Proxy`代理访问`Pod`，从而访问集群中的`Nginx`服务。
7. `Controller-Manager`负责监控集群状态，并确保系统达到预期状态。它包含不同的控制器，保证`Node`节点的状态符合预期，维护`Pod`的数量等。

